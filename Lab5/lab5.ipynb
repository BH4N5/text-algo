{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laboratorium 5.\n",
    "#### Bartosz Hanc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Zaimplementuj algorytm wyszukiwania wzorca 2-wymiarowego. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Sequence, Hashable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, symb) -> None:\n",
    "        self.next: dict[Hashable, Node] = {}\n",
    "        self.fail: Node = None\n",
    "        self.symb: str = symb\n",
    "        self.term: int = -1\n",
    "\n",
    "\n",
    "class Trie:\n",
    "    def __init__(self, patterns) -> None:\n",
    "        self.root = Node(symb=\"\")\n",
    "        self.__build_trie(patterns=patterns)\n",
    "\n",
    "    def __build_trie(self, patterns: Sequence[Sequence[Hashable]]):\n",
    "        for i, pattern in enumerate(patterns):\n",
    "            node = self.root\n",
    "            for c in pattern:\n",
    "                if c in node.next:\n",
    "                    node = node.next[c]\n",
    "                else:\n",
    "                    child = Node(symb=str(c))\n",
    "                    node.next[c] = child\n",
    "                    node = child\n",
    "\n",
    "            node.term = i\n",
    "\n",
    "    def __repr__(self):\n",
    "        def rec_print(node, level=0):\n",
    "            line = \"\" if level == 0 else \"┕━━━━ \"\n",
    "            ret = \"\\t\" * level + line + node.symb + \"\\n\"\n",
    "\n",
    "            for _, child in node.next.items():\n",
    "                ret += rec_print(child, level + 1)\n",
    "\n",
    "            return ret\n",
    "\n",
    "        return rec_print(self.root)\n",
    "\n",
    "    def build_automaton(self, alphabet: Sequence[Hashable]):\n",
    "        from collections import deque\n",
    "\n",
    "        queue = deque()\n",
    "        root = self.root\n",
    "\n",
    "        for c in alphabet:\n",
    "            if c in root.next:\n",
    "                node = root.next[c]\n",
    "                node.fail = root\n",
    "                queue.append(node)\n",
    "            else:\n",
    "                root.next[c] = root\n",
    "\n",
    "        while len(queue) > 0:\n",
    "            node: Node = queue.popleft()\n",
    "\n",
    "            for c in alphabet:\n",
    "                if c in node.next:\n",
    "                    next: Node = node.next[c]\n",
    "                    queue.append(next)\n",
    "                    x = node.fail\n",
    "\n",
    "                    while c not in x.next:\n",
    "                        x = x.fail\n",
    "\n",
    "                    next.fail = x.next[c]\n",
    "\n",
    "\n",
    "def Aho_Corasick(trie: Trie, text):\n",
    "    node: Node = trie.root\n",
    "    ans = []\n",
    "\n",
    "    for i, c in enumerate(text):\n",
    "        while c not in node.next:\n",
    "            node = node.fail\n",
    "\n",
    "        node = node.next[c]\n",
    "        if node.term > -1:\n",
    "            ans.append((i, node.term))\n",
    "\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t┕━━━━ a\n",
      "\t\t┕━━━━ b\n",
      "\t┕━━━━ b\n",
      "\t\t┕━━━━ c\n",
      "\t\t\t┕━━━━ a\n",
      "\t\t\t┕━━━━ b\n",
      "\t\t\t\t┕━━━━ a\n",
      "\t\t┕━━━━ a\n",
      "\t┕━━━━ c\n",
      "\t\t┕━━━━ a\n",
      "\t\t\t┕━━━━ a\n",
      "\t\t\t┕━━━━ b\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(Trie([\"ab\", \"bc\", \"bca\", \"bcb\", \"caa\", \"cab\", \"ba\", \"bcba\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 dolor\n",
      "48 in\n",
      "80 in\n",
      "107 dolor\n",
      "108 dolore\n",
      "137 in\n",
      "252 dolor\n",
      "255 in\n",
      "272 in\n",
      "293 esse\n",
      "306 dolor\n",
      "307 dolore\n",
      "347 in\n",
      "389 in\n"
     ]
    }
   ],
   "source": [
    "text = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\"\n",
    "alphabet = set(text)\n",
    "\n",
    "patterns = [\"dolor\", \"esse\", \"dolore\", \"in\"]\n",
    "trie = Trie(patterns)\n",
    "trie.build_automaton(alphabet=alphabet)\n",
    "\n",
    "for i, pat_idx in Aho_Corasick(trie=trie, text=text):\n",
    "    print(i, patterns[pat_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_2d(pattern_2d: np.array, text: np.array):\n",
    "    patterns = np.unique(pattern_2d.T, axis=0)\n",
    "    trie = Trie(patterns)\n",
    "    trie.build_automaton(alphabet=set(text.flatten()))\n",
    "\n",
    "    N = np.array([[-1 for _ in range(len(text[0]))] for _ in range(len(text))])\n",
    "\n",
    "    for col, s in enumerate(text.T):\n",
    "        for row, pat_idx in Aho_Corasick(trie=trie, text=s):\n",
    "            N[row][col] = pat_idx\n",
    "\n",
    "    pattern_1d = np.array([], dtype=np.int64)\n",
    "    for pattern in pattern_2d.T:\n",
    "        for i, other in enumerate(patterns):\n",
    "            if np.array_equal(pattern, other):\n",
    "                pattern_1d = np.append(pattern_1d, i)\n",
    "                break\n",
    "\n",
    "    ans = []\n",
    "    n = len(pattern_1d)\n",
    "    for row, s in enumerate(N):\n",
    "        for col in range(len(s)):\n",
    "            if col + n < len(s) and np.array_equal(pattern_1d, s[col : col + n]):\n",
    "                ans.append((row, col + n - 1))\n",
    "\n",
    "    return ans\n",
    "\n",
    "\n",
    "def show(ans, text_array, pat_shape, extr_space=False):\n",
    "    n, m = pat_shape\n",
    "    MARK = \"\\033[91m\"\n",
    "    ENDC = \"\\033[0m\"\n",
    "\n",
    "    show = text_array.tolist()\n",
    "    for row, col in ans:\n",
    "        for i in range(row - n + 1, row + 1):\n",
    "            for j in range(col - m + 1, col + 1):\n",
    "                show[i][j] = MARK + show[i][j] + ENDC\n",
    "\n",
    "    m = \" \" if extr_space else \"\"\n",
    "    print(\"\\n\".join([m.join(s) for s in show]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 3), (4, 5), (5, 2)] \n",
      "\n",
      "a b a b a b b\n",
      "a \u001b[91ma\u001b[0m \u001b[91ma\u001b[0m \u001b[91ma\u001b[0m b b b\n",
      "b \u001b[91mb\u001b[0m \u001b[91mb\u001b[0m \u001b[91m\u001b[91ma\u001b[0m\u001b[0m \u001b[91ma\u001b[0m \u001b[91ma\u001b[0m b\n",
      "\u001b[91ma\u001b[0m \u001b[91m\u001b[91ma\u001b[0m\u001b[0m \u001b[91m\u001b[91ma\u001b[0m\u001b[0m \u001b[91m\u001b[91mb\u001b[0m\u001b[0m \u001b[91mb\u001b[0m \u001b[91ma\u001b[0m a\n",
      "\u001b[91mb\u001b[0m \u001b[91mb\u001b[0m \u001b[91ma\u001b[0m \u001b[91ma\u001b[0m \u001b[91ma\u001b[0m \u001b[91mb\u001b[0m b\n",
      "\u001b[91ma\u001b[0m \u001b[91ma\u001b[0m \u001b[91mb\u001b[0m a a a a\n"
     ]
    }
   ],
   "source": [
    "pattern = np.array(list(map(lambda x: x.split(\" \"), [\"a a a\", \"b b a\", \"a a b\"])))\n",
    "text = np.array(\n",
    "    list(\n",
    "        map(\n",
    "            lambda x: x.split(\" \"),\n",
    "            [\n",
    "                \"a b a b a b b\",\n",
    "                \"a a a a b b b\",\n",
    "                \"b b b a a a b\",\n",
    "                \"a a a b b a a\",\n",
    "                \"b b a a a b b\",\n",
    "                \"a a b a a a a\",\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "ans = match_2d(pattern_2d=pattern, text=text)\n",
    "print(ans, \"\\n\")\n",
    "show(ans, text, pattern.shape, extr_space=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Znajdź w załączonym pliku \"haystack.txt\" wszystkie sytuacje, gdy taka sama litera występuje na\n",
    "   tej samej pozycji w dwóch kolejnych linijkach. Zwróć uwagę, na nierówną długość linii w pliku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of \u001b[91mt\u001b[0mhe simplest and n a t u r a l types of information repr\u001b[91me\u001b[0msentation is by me\u001b[91ma\u001b[0m\u001b[91mn\u001b[0ms                    \n",
      "of \u001b[91mw\u001b[0m\u001b[91mr\u001b[0m\u001b[91mi\u001b[0m\u001b[91mt\u001b[0m\u001b[91m\u001b[91mt\u001b[0m\u001b[0m\u001b[91me\u001b[0m\u001b[91mn\u001b[0m texts. This type of d a t a is characterized by t h \u001b[91me\u001b[0m fact t h a t it c\u001b[91ma\u001b[0m\u001b[91mn\u001b[0m                     \n",
      "be \u001b[91mw\u001b[0m\u001b[91mr\u001b[0m\u001b[91mi\u001b[0m\u001b[91mt\u001b[0m\u001b[91mt\u001b[0m\u001b[91me\u001b[0m\u001b[91mn\u001b[0m down as a long sequence of characters. Such linear a sequence                                 \n",
      "is called a text. T h e texts \u001b[91ma\u001b[0mre cen\u001b[91mt\u001b[0mral in \"word pro\u001b[91mc\u001b[0mes\u001b[91ms\u001b[0ming\" \u001b[91ms\u001b[0mystems, which                            \n",
      "provide facili\u001b[91mt\u001b[0mies for \u001b[91mt\u001b[0m h e m\u001b[91ma\u001b[0mnipula\u001b[91mt\u001b[0mion of text\u001b[91ms\u001b[0m. Su\u001b[91mc\u001b[0mh \u001b[91ms\u001b[0mystem\u001b[91ms\u001b[0m usually pr\u001b[91mo\u001b[0mc\u001b[91me\u001b[0mss                         \n",
      "objects t h a \u001b[91mt\u001b[0m are qui\u001b[91mt\u001b[0me large. For example, thi\u001b[91ms\u001b[0m book prob\u001b[91ma\u001b[0mbly c\u001b[91mo\u001b[0mntains m\u001b[91mo\u001b[0mr\u001b[91me\u001b[0m                           \n",
      "t h a n a million characters. Text alg\u001b[91mo\u001b[0m\u001b[91mr\u001b[0mithms occu\u001b[91mr\u001b[0m in many \u001b[91ma\u001b[0mre\u001b[91ma\u001b[0ms \u001b[91mo\u001b[0mf science and                         \n",
      "information p\u001b[91mr\u001b[0mocessing. Many \u001b[91mt\u001b[0mext edit\u001b[91m\u001b[91mo\u001b[0m\u001b[0m\u001b[91mr\u001b[0ms and prog\u001b[91mr\u001b[0mamming langu\u001b[91ma\u001b[0mg\u001b[91me\u001b[0ms have                                 \n",
      "facilities fo\u001b[91mr\u001b[0m proces\u001b[91ms\u001b[0ming tex\u001b[91mt\u001b[0ms. In b\u001b[91mi\u001b[0m\u001b[91mo\u001b[0mlogy, text algorithms aris\u001b[91me\u001b[0m in the s\u001b[91mt\u001b[0mudy                          \n",
      "of molecular sequence\u001b[91ms\u001b[0m. T h e complex\u001b[91mi\u001b[0mty of text algorithm\u001b[91ms\u001b[0m \u001b[91mi\u001b[0ms also one of \u001b[91mt\u001b[0m h e                         \n",
      "c\u001b[91me\u001b[0mntral and most studied pr\u001b[91mo\u001b[0mblems in theoreti\u001b[91mc\u001b[0mal computer \u001b[91ms\u001b[0mc\u001b[91mi\u001b[0menc\u001b[91me\u001b[0m. It could                              \n",
      "b\u001b[91me\u001b[0m said t h a t it is the d\u001b[91mo\u001b[0mmain in which pra\u001b[91mc\u001b[0mtice and theory ar\u001b[91me\u001b[0m very close to                          \n",
      "each other.                                                                                              \n",
      "T h e basi\u001b[91mc\u001b[0m textual problem in stringology is called pa\u001b[91mt\u001b[0mtern matching. It is                             \n",
      "us\u001b[91me\u001b[0md to ac\u001b[91mc\u001b[0mess information and, no doubt, at this mome\u001b[91mn\u001b[0m\u001b[91mt\u001b[0m m a n y computers                               \n",
      "ar\u001b[91me\u001b[0m solving \u001b[91mt\u001b[0mhis p\u001b[91mr\u001b[0moblem as a frequently us\u001b[91me\u001b[0md operatio\u001b[91mn\u001b[0m in s\u001b[91mo\u001b[0mme application                              \n",
      "sys\u001b[91mt\u001b[0me\u001b[91mm\u001b[0m. P a \u001b[91mt\u001b[0m t e \u001b[91mr\u001b[0m n matching is comparabl\u001b[91me\u001b[0m in this sense t\u001b[91mo\u001b[0m sorting, or to basic                       \n",
      "ari\u001b[91mt\u001b[0mh\u001b[91mm\u001b[0m\u001b[91me\u001b[0mtic ope\u001b[91mr\u001b[0mations.                                                                                   \n",
      "Consid\u001b[91me\u001b[0mr the p\u001b[91mr\u001b[0moblem of a r\u001b[91me\u001b[0mader of the French dictionary \" G r a n d Larousse,\"                         \n",
      "who wants all entries relat\u001b[91me\u001b[0md to \u001b[91mt\u001b[0mhe \u001b[91mn\u001b[0m a m e \"Marie-Cu\u001b[91mr\u001b[0m\u001b[91mi\u001b[0me-Sklodowska.\" This is                           \n",
      "a n ex\u001b[91ma\u001b[0mmpl\u001b[91me\u001b[0m of a p a t t e r n ma\u001b[91mt\u001b[0mchi\u001b[91mn\u001b[0mg problem, or st\u001b[91m\u001b[91mr\u001b[0m\u001b[0m\u001b[91mi\u001b[0m\u001b[91mn\u001b[0mg matching. In this case,                       \n",
      "the n \u001b[91ma\u001b[0m m \u001b[91me\u001b[0m \"Marie-Curie-Sklodowska\" is the p a t t e \u001b[91mr\u001b[0m \u001b[91mn\u001b[0m . G\u001b[91me\u001b[0m\u001b[91mn\u001b[0merally \u001b[91mw\u001b[0me m a y want to                   \n",
      "find a s\u001b[91mt\u001b[0mring called a pattern of length m inside a t\u001b[91me\u001b[0mxt of l\u001b[91me\u001b[0m\u001b[91mn\u001b[0mgth n, \u001b[91mw\u001b[0mhere n is                         \n",
      "grea\u001b[91mt\u001b[0mer \u001b[91mt\u001b[0m h a n m. T h e p a t t e r n can be describ\u001b[91me\u001b[0md in a more complex way to denote                  \n",
      "a s\u001b[91me\u001b[0m\u001b[91m\u001b[91mt\u001b[0m\u001b[0m of strings and not just a single word. In many cases n is v\u001b[91me\u001b[0mry large. In                           \n",
      "gen\u001b[91me\u001b[0m\u001b[91mt\u001b[0mics the p a t t e r n can correspond to a gene t h a t can b\u001b[91me\u001b[0m very long; in image                   \n",
      "                                                                                                         \n",
      "T \u001b[91mh\u001b[0m e search of w\u001b[91mo\u001b[0mrds or p a t \u001b[91mt\u001b[0m e r n s in static texts is quite a different question                   \n",
      "t \u001b[91mh\u001b[0m a n the previ\u001b[91m\u001b[91mo\u001b[0m\u001b[0mus pa\u001b[91mt\u001b[0mtern-ma\u001b[91mt\u001b[0mching mechani\u001b[91ms\u001b[0mm. Dic\u001b[91mt\u001b[0mionaries, fo\u001b[91mr\u001b[0m \u001b[91me\u001b[0m\u001b[91mx\u001b[0m\u001b[91ma\u001b[0m\u001b[91mm\u001b[0m\u001b[91mp\u001b[0m\u001b[91ml\u001b[0m\u001b[91me\u001b[0m,                              \n",
      "are organized in \u001b[91mo\u001b[0mrder \u001b[91mt\u001b[0mo speed u p th\u001b[91me\u001b[0m acc\u001b[91me\u001b[0ms\u001b[91ms\u001b[0m to en\u001b[91mt\u001b[0mrie\u001b[91ms\u001b[0m. Anothe\u001b[91mr\u001b[0m \u001b[91me\u001b[0m\u001b[91mx\u001b[0m\u001b[91ma\u001b[0m\u001b[91mm\u001b[0m\u001b[91mp\u001b[0m\u001b[91ml\u001b[0m\u001b[91me\u001b[0m                               \n",
      "of the same ques\u001b[91mt\u001b[0mion is given by index\u001b[91me\u001b[0ms. T\u001b[91me\u001b[0mchnical book\u001b[91m\u001b[91ms\u001b[0m\u001b[0m \u001b[91mo\u001b[0m\u001b[91mf\u001b[0mten contain a n                              \n",
      "\u001b[91mi\u001b[0m\u001b[91mn\u001b[0mdex of chosen \u001b[91mt\u001b[0merms t h a t g\u001b[91mi\u001b[0mves pointers to p \u001b[91ma\u001b[0m r t \u001b[91ms\u001b[0m \u001b[91mo\u001b[0m\u001b[91mf\u001b[0m the text \u001b[91mr\u001b[0mel\u001b[91ma\u001b[0mted to words                   \n",
      "\u001b[91mi\u001b[0m\u001b[91mn\u001b[0m the index. T h e algorithms \u001b[91mi\u001b[0mnv\u001b[91mo\u001b[0mlved in the cre\u001b[91ma\u001b[0mtion of an index fo\u001b[91mr\u001b[0mm \u001b[91ma\u001b[0m                               \n",
      "specific g\u001b[91mr\u001b[0m\u001b[91mo\u001b[0mup. T h e use \u001b[91mo\u001b[0mf dicti\u001b[91mo\u001b[0mna\u001b[91mr\u001b[0mies or \u001b[91ml\u001b[0mexicons is often rel\u001b[91ma\u001b[0mted t o n a t u r a l                 \n",
      "language p\u001b[91mr\u001b[0m\u001b[91mo\u001b[0mcessing. Lexic\u001b[91mo\u001b[0mns of prog\u001b[91mr\u001b[0mam\u001b[91mm\u001b[0ming \u001b[91ml\u001b[0manguages are s\u001b[91mm\u001b[0mall, \u001b[91ma\u001b[0mnd their                              \n",
      "representa\u001b[91mt\u001b[0mion is \u001b[91mn\u001b[0mot a difficult proble\u001b[91mm\u001b[0m during the develop\u001b[91mm\u001b[0ment of a compiler.                          \n",
      "To the con\u001b[91mt\u001b[0mrary, E\u001b[91mn\u001b[0mglish contains approximately 100,000 words, a n d even twice                          \n",
      "\u001b[91mt\u001b[0m \u001b[91mh\u001b[0m \u001b[91ma\u001b[0m t if inflecte\u001b[91md\u001b[0m forms are con\u001b[91ms\u001b[0midered. In Fr\u001b[91me\u001b[0mnch, inflected forms produce more                       \n",
      "\u001b[91mt\u001b[0m \u001b[91mh\u001b[0m \u001b[91ma\u001b[0m n 700,000 wor\u001b[91md\u001b[0ms. T h e repre\u001b[91ms\u001b[0mentation of l\u001b[91me\u001b[0mxicons of this size makes the                           \n",
      "problem a bit more challenging.                                                                          \n",
      "A simple us\u001b[91me\u001b[0m of dictionari\u001b[91me\u001b[0ms is illustrated by spelling checker\u001b[91ms\u001b[0m. T h e UNIX                             \n",
      "\u001b[91mc\u001b[0m\u001b[91mo\u001b[0mmmand, sp\u001b[91me\u001b[0mll, re\u001b[91mp\u001b[0morts th\u001b[91me\u001b[0m words in its inpu\u001b[91mt\u001b[0m t h a t ar\u001b[91me\u001b[0m not \u001b[91ms\u001b[0mtored in \u001b[91mt\u001b[0mhe \u001b[91ml\u001b[0mexi-                       \n",
      "\u001b[91mc\u001b[0m\u001b[91mo\u001b[0mn. This rough ap\u001b[91mp\u001b[0mroach does not yi\u001b[91me\u001b[0mld a per\u001b[91mt\u001b[0min\u001b[91me\u001b[0mnt check\u001b[91me\u001b[0mr, b u t , prac\u001b[91mt\u001b[0mica\u001b[91ml\u001b[0mly,                        \n",
      "it helps to find typing e\u001b[91mr\u001b[0mrors. T h \u001b[91me\u001b[0m lexicon us\u001b[91me\u001b[0md by spell contains approxi-                            \n",
      "\u001b[91mm\u001b[0matel\u001b[91my\u001b[0m 70,000 entries sto\u001b[91mr\u001b[0med with\u001b[91mi\u001b[0mn less t h a n 60 kil\u001b[91mo\u001b[0mbytes of random-access                           \n",
      "\u001b[91mm\u001b[0memor\u001b[91my\u001b[0m. Quick access to lexicons \u001b[91mi\u001b[0m\u001b[91ms\u001b[0m a necessary conditi\u001b[91mo\u001b[0mn for producing good                             \n",
      "parsers. T h e d a t a s\u001b[91mt\u001b[0mructure u\u001b[91ms\u001b[0meful fo\u001b[91mr\u001b[0m \u001b[91ms\u001b[0much acc\u001b[91me\u001b[0mss is ca\u001b[91ml\u001b[0mled an index. In our                       \n",
      "book indexes correspond \u001b[91mt\u001b[0mo d a t a st\u001b[91mr\u001b[0muctu\u001b[91mr\u001b[0me\u001b[91ms\u001b[0m repr\u001b[91me\u001b[0ms\u001b[91me\u001b[0mnting al\u001b[91ml\u001b[0m factors of a given                        \n",
      "(presumably long) text. We consider p\u001b[91mr\u001b[0moblems relat\u001b[91me\u001b[0md to the construction of                              \n",
      "such structure\u001b[91ms\u001b[0m: suffix t r e e s , d i r e c t e d a c y c l i c w o r d g r a p h s , f a c t o r a u -\n",
      "\u001b[91mt\u001b[0m \u001b[91mo\u001b[0m m a t a , \u001b[91ms\u001b[0muffix arrays. T h e PAT                                                                   \n",
      "\u001b[91mt\u001b[0mo\u001b[91mo\u001b[0ml developed at the N O E D C\u001b[91me\u001b[0m\u001b[91mn\u001b[0m\u001b[91mt\u001b[0mer                                                                     \n",
      "(Wate\u001b[91mr\u001b[0mlo\u001b[91mo\u001b[0m, C\u001b[91ma\u001b[0mnada) is an implem\u001b[91me\u001b[0m\u001b[91mn\u001b[0m\u001b[91mt\u001b[0mation of one of the\u001b[91ms\u001b[0me struc\u001b[91mt\u001b[0mures ta\u001b[91mi\u001b[0mlored                              \n",
      "t\u001b[91mo\u001b[0m wo\u001b[91mr\u001b[0mk \u001b[91mo\u001b[0mn l\u001b[91m\u001b[91ma\u001b[0m\u001b[0mrge texts. There are several app\u001b[91ml\u001b[0mic\u001b[91ma\u001b[0mtion\u001b[91ms\u001b[0m t h a \u001b[91mt\u001b[0m effect\u001b[91mi\u001b[0mvely require                       \n",
      "\u001b[91ms\u001b[0m\u001b[91mo\u001b[0mme unders\u001b[91mt\u001b[0m\u001b[91ma\u001b[0mnding of phrases in \u001b[91mn\u001b[0m a t u r a \u001b[91ml\u001b[0m l\u001b[91ma\u001b[0mnguages, such as d a t a retrieval                      \n",
      "\u001b[91ms\u001b[0mystems, in\u001b[91mt\u001b[0meract\u001b[91mi\u001b[0mve software, a \u001b[91mn\u001b[0m d cha\u001b[91mr\u001b[0macter recogni\u001b[91mt\u001b[0mion.                                              \n",
      "An image sc\u001b[91ma\u001b[0mn\u001b[91mn\u001b[0mer \u001b[91mi\u001b[0ms a kind of p\u001b[91mh\u001b[0motocopie\u001b[91mr\u001b[0m. It is used \u001b[91mt\u001b[0mo give a digitized                                \n",
      "version of \u001b[91ma\u001b[0m \u001b[91mn\u001b[0m image. W h e n t\u001b[91mh\u001b[0me im\u001b[91ma\u001b[0mge is a page of t\u001b[91me\u001b[0mxt, the n a t u r a l o u t p u t of the          \n",
      "scanner must be in a digital form av\u001b[91m\u001b[91ma\u001b[0m\u001b[0milable t\u001b[91mo\u001b[0m a \u001b[91mt\u001b[0m\u001b[91me\u001b[0mxt \u001b[91m\u001b[91me\u001b[0m\u001b[0mditor. T h e transforma\u001b[91mt\u001b[0mion                       \n",
      "of a digitized image of \u001b[91ma\u001b[0m text in\u001b[91mt\u001b[0mo \u001b[91ma\u001b[0m usual c\u001b[91mo\u001b[0mmpu\u001b[91mt\u001b[0m\u001b[91me\u001b[0mr r\u001b[91me\u001b[0mpresentation of th\u001b[91me\u001b[0m \u001b[91mt\u001b[0mex\u001b[91mt\u001b[0m                          \n",
      "is realized by a n Optic\u001b[91ma\u001b[0ml Cha\u001b[91mr\u001b[0mac\u001b[91mt\u001b[0mer Recognit\u001b[91mi\u001b[0mon ( O C R ) . Scanning a t\u001b[91me\u001b[0mx\u001b[91mt\u001b[0m with                        \n",
      "an O C R can be 50 times faste\u001b[91mr\u001b[0m t h a n retyp\u001b[91mi\u001b[0mng the tex\u001b[91mt\u001b[0m on a keyboard. T h u s ,                       \n",
      "O C R softwares are likely to become mo\u001b[91mr\u001b[0me common. B u t \u001b[91mt\u001b[0mhey still suffer from                           \n",
      "a high degree of imprecision. T h e ave\u001b[91mr\u001b[0mage rate of error in the r\u001b[91me\u001b[0mcognition of                          \n",
      "ch\u001b[91ma\u001b[0mracters is \u001b[91ma\u001b[0mpproxim\u001b[91ma\u001b[0mtely o\u001b[91mn\u001b[0me percent. Even if this may h a p p \u001b[91me\u001b[0m n to be rather                       \n",
      "sm\u001b[91ma\u001b[0mll, this me\u001b[91ma\u001b[0mns t h \u001b[91ma\u001b[0m t sca\u001b[91mn\u001b[0mning \u001b[91ma\u001b[0m book produces approximately one \u001b[91me\u001b[0mrror per                           \n",
      "line. This is compared with the usu\u001b[91ma\u001b[0mlly very high quality of texts ch\u001b[91me\u001b[0mck\u001b[91me\u001b[0md                               \n",
      "by specialists. T\u001b[91me\u001b[0mchnical imp\u001b[91mr\u001b[0moveme\u001b[91mn\u001b[0mt\u001b[91ms\u001b[0m o\u001b[91mn\u001b[0m the hardware ca\u001b[91mn\u001b[0m help elimina\u001b[91mt\u001b[0m\u001b[91me\u001b[0m                                \n",
      "\u001b[91mc\u001b[0mertain kinds of \u001b[91me\u001b[0mrrors occur\u001b[91mr\u001b[0ming o\u001b[91mn\u001b[0m \u001b[91ms\u001b[0mca\u001b[91mn\u001b[0mned t\u001b[91me\u001b[0mxts \u001b[91mi\u001b[0mn pri\u001b[91mn\u001b[0mted forms. Bu\u001b[91mt\u001b[0m this                            \n",
      "\u001b[91mc\u001b[0manno\u001b[91mt\u001b[0m alleviat\u001b[91me\u001b[0m the p\u001b[91mr\u001b[0moblem associ\u001b[91ma\u001b[0mted with r\u001b[91me\u001b[0mcogn\u001b[91mi\u001b[0mzing texts in printed forms.                         \n",
      "Reduc\u001b[91mt\u001b[0mion of th\u001b[91me\u001b[0m numbe\u001b[91mr\u001b[0m of errors c\u001b[91ma\u001b[0mn thu\u001b[91ms\u001b[0m only b\u001b[91me\u001b[0m achieved by considering the                           \n",
      "con\u001b[91mt\u001b[0mext of the character\u001b[91ms\u001b[0m, which assum\u001b[91me\u001b[0ms \u001b[91ms\u001b[0m\u001b[91mo\u001b[0mme und\u001b[91me\u001b[0mrstanding of the structure                             \n",
      "of \u001b[91m\u001b[91mt\u001b[0m\u001b[0mhe tex\u001b[91mt\u001b[0m. Image proc\u001b[91me\u001b[0m\u001b[91ms\u001b[0msing is relat\u001b[91me\u001b[0md t\u001b[91mo\u001b[0m the problem of \u001b[91mt\u001b[0mwo-dimensional                               \n",
      "pat\u001b[91mt\u001b[0mern ma\u001b[91mt\u001b[0mc\u001b[91mh\u001b[0m\u001b[91mi\u001b[0mng. Anoth\u001b[91me\u001b[0mr r\u001b[91me\u001b[0mlated problem is the data struc\u001b[91mt\u001b[0mure for all                                  \n",
      "subimages, w\u001b[91mh\u001b[0m\u001b[91mi\u001b[0mch is discuss\u001b[91me\u001b[0md in this book in the context of the dictionary                              \n",
      "of basic factors.                                                                                        \n",
      "The th\u001b[91me\u001b[0moretical appro\u001b[91ma\u001b[0mch to the representation of lexicons is either by me\u001b[91ma\u001b[0mns                            \n",
      "o\u001b[91mf\u001b[0m tre\u001b[91m\u001b[91me\u001b[0m\u001b[0ms or f\u001b[91mi\u001b[0mnite st\u001b[91ma\u001b[0m\u001b[91mt\u001b[0me automata. It appe\u001b[91ma\u001b[0mrs that both appro\u001b[91ma\u001b[0mches are equ\u001b[91ma\u001b[0mlly                           \n",
      "e\u001b[91mf\u001b[0mfici\u001b[91me\u001b[0mnt. Th\u001b[91mi\u001b[0ms shows \u001b[91mt\u001b[0mhe practical import\u001b[91ma\u001b[0mnce of the autom\u001b[91ma\u001b[0mt\u001b[91ma\u001b[0m th\u001b[91me\u001b[0moretic                                 \n",
      "approach t\u001b[91mo\u001b[0m text problem\u001b[91ms\u001b[0m. At LITP (P\u001b[91ma\u001b[0mris) and IGM (Marne-l\u001b[91ma\u001b[0m-Vall\u001b[91me\u001b[0me)                                     \n",
      "we hav\u001b[91me\u001b[0m sh\u001b[91mo\u001b[0mwn that the u\u001b[91ms\u001b[0me of automat\u001b[91ma\u001b[0m to represent lexicons is particularly                             \n",
      "effici\u001b[91me\u001b[0mnt. Exp\u001b[91me\u001b[0mriments have been done on a 700,000 w\u001b[91mo\u001b[0mrd lexicon of LADL                                  \n",
      "(Paris). The r\u001b[91me\u001b[0mpresentation supports dire\u001b[91mc\u001b[0mt acc\u001b[91me\u001b[0mss t\u001b[91mo\u001b[0m any word of the lexicon                            \n",
      "and takes only 300 kilobytes of random-ac\u001b[91mc\u001b[0mess m\u001b[91me\u001b[0mmory.                                                    \n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "text = open(\"haystack.txt\", \"r\").read().splitlines()\n",
    "MAX_LEN = len(max(text, key=lambda x: len(x)))\n",
    "text = list(\n",
    "    map(lambda x: list(x), list(map(lambda x: x + \" \" * (MAX_LEN - len(x)), text)))\n",
    ")\n",
    "text = np.array(text)\n",
    "\n",
    "ans = []\n",
    "for c in string.ascii_letters:\n",
    "    pattern = np.array([[c], [c]])\n",
    "    ans += match_2d(pattern, text)\n",
    "\n",
    "show(ans, text, (2, 1))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Znajdź wszystkie wystąpienia \"th\" oraz \"t h\" w dwóch kolejnych liniach na tej samej pozycji. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the simplest and n a t u r a l types of information representation is by means                    \n",
      "of written texts. This type of d a t a is characterized by t h e fact t h a t it can                     \n",
      "be written down as a long sequence of characters. Such linear a sequence                                 \n",
      "is called a text. T h e texts are central in \"word processing\" systems, which                            \n",
      "provide facilities for t h e manipulation of texts. Such systems usually process                         \n",
      "objects t h a t are quite large. For example, this book probably contains more                           \n",
      "t h a n a million characters. Text algorithms occur in many areas of science and                         \n",
      "information processing. Many text editors and programming languages have                                 \n",
      "facilities for processing texts. In biology, text algorithms arise in the study                          \n",
      "of molecular sequences. T h e complexity of text algorithms is also one of t h e                         \n",
      "central and most studied problems in theoretical computer science. It could                              \n",
      "be said t h a t it is the domain in which practice and theory are very close to                          \n",
      "each other.                                                                                              \n",
      "T h e basic textual problem in stringology is called pattern matching. It is                             \n",
      "used to access information and, no doubt, at this moment m a n y computers                               \n",
      "are solving this problem as a frequently used operation in some application                              \n",
      "system. P a t t e r n matching is comparable in this sense to sorting, or to basic                       \n",
      "arithmetic operations.                                                                                   \n",
      "Consider the problem of a reader of the French dictionary \" G r a n d Larousse,\"                         \n",
      "who wants all entries related to the n a m e \"Marie-Curie-Sklodowska.\" This is                           \n",
      "a n example of a p a t t e r n matching problem, or string matching. In this case,                       \n",
      "the n a m e \"Marie-Curie-Sklodowska\" is the p a t t e r n . Generally we m a y want to                   \n",
      "find a string called a pattern of length m inside a text of length n, where n is                         \n",
      "greater t h a n m. T h e p a t t e r n can be described in a more complex way to denote                  \n",
      "a set of strings and not just a single word. In many cases n is very large. In                           \n",
      "genetics the p a t t e r n can correspond to a gene t h a t can be very long; in image                   \n",
      "                                                                                                         \n",
      "T h e search of words or p a t t e r n s in static texts is quite a different question                   \n",
      "t h a n the previous pattern-matching mechanism. Dictionaries, for example,                              \n",
      "are organized in order to speed u p the access to entries. Another example                               \n",
      "of the same question is given by indexes. Technical books often contain a n                              \n",
      "index of chosen terms t h a t gives pointers to p a r t s of the text related to words                   \n",
      "in the index. T h e algorithms involved in the creation of an index form a                               \n",
      "specific group. T h e use of dictionaries or lexicons is often related t o n a t u r a l                 \n",
      "language processing. Lexicons of programming languages are small, and their                              \n",
      "representation is not a difficult problem during the development of a compiler.                          \n",
      "To the contrary, English contains approximately 100,000 words, a n d even twice                          \n",
      "\u001b[91m\u001b[91mt\u001b[0m\u001b[0m\u001b[91m\u001b[91m \u001b[0m\u001b[0m\u001b[91m\u001b[91mh\u001b[0m\u001b[0m a t if inflected forms are considered. In French, inflected forms produce more                       \n",
      "\u001b[91m\u001b[91mt\u001b[0m\u001b[0m\u001b[91m\u001b[91m \u001b[0m\u001b[0m\u001b[91m\u001b[91mh\u001b[0m\u001b[0m a n 700,000 words. T h e representation of lexicons of this size makes the                           \n",
      "problem a bit more challenging.                                                                          \n",
      "A simple use of dictionaries is illustrated by spelling checkers. T h e UNIX                             \n",
      "command, spell, reports the words in its input t h a t are not stored in the lexi-                       \n",
      "con. This rough approach does not yield a pertinent checker, b u t , practically,                        \n",
      "it helps to find typing errors. T h e lexicon used by spell contains approxi-                            \n",
      "mately 70,000 entries stored within less t h a n 60 kilobytes of random-access                           \n",
      "memory. Quick access to lexicons is a necessary condition for producing good                             \n",
      "parsers. T h e d a t a structure useful for such access is called an index. In our                       \n",
      "book indexes correspond to d a t a structures representing all factors of a given                        \n",
      "(presumably long) text. We consider problems related to the construction of                              \n",
      "such structures: suffix t r e e s , d i r e c t e d a c y c l i c w o r d g r a p h s , f a c t o r a u -\n",
      "t o m a t a , suffix arrays. T h e PAT                                                                   \n",
      "tool developed at the N O E D Center                                                                     \n",
      "(Waterloo, Canada) is an implementation of one of these structures tailored                              \n",
      "to work on large texts. There are several applications t h a t effectively require                       \n",
      "some understanding of phrases in n a t u r a l languages, such as d a t a retrieval                      \n",
      "systems, interactive software, a n d character recognition.                                              \n",
      "An image scanner is a kind of photocopier. It is used to give a digitized                                \n",
      "version of a n image. W h e n the image is a page of text, the n a t u r a l o u t p u t of the          \n",
      "scanner must be in a digital form available to a text editor. T h e transformation                       \n",
      "of a digitized image of a text into a usual computer representation of the text                          \n",
      "is realized by a n Optical Character Recognition ( O C R ) . Scanning a text with                        \n",
      "an O C R can be 50 times faster t h a n retyping the text on a keyboard. T h u s ,                       \n",
      "O C R softwares are likely to become more common. B u t they still suffer from                           \n",
      "a high degree of imprecision. T h e average rate of error in the recognition of                          \n",
      "characters is approximately one percent. Even if this may h a p p e n to be rather                       \n",
      "small, this means t h a t scanning a book produces approximately one error per                           \n",
      "line. This is compared with the usually very high quality of texts checked                               \n",
      "by specialists. Technical improvements on the hardware can help eliminate                                \n",
      "certain kinds of errors occurring on scanned texts in printed forms. But this                            \n",
      "cannot alleviate the problem associated with recognizing texts in printed forms.                         \n",
      "Reduction of the number of errors can thus only be achieved by considering the                           \n",
      "context of the characters, which assumes some understanding of the structure                             \n",
      "of the text. Image processing is related to the problem of two-dimensional                               \n",
      "pattern matching. Another related problem is the data structure for all                                  \n",
      "subimages, which is discussed in this book in the context of the dictionary                              \n",
      "of basic factors.                                                                                        \n",
      "The theoretical approach to the representation of lexicons is either by means                            \n",
      "of trees or finite state automata. It appears that both approaches are equally                           \n",
      "efficient. This shows the practical importance of the automata theoretic                                 \n",
      "approach to text problems. At LITP (Paris) and IGM (Marne-la-Vallee)                                     \n",
      "we have shown that the use of automata to represent lexicons is particularly                             \n",
      "efficient. Experiments have been done on a 700,000 word lexicon of LADL                                  \n",
      "(Paris). The representation supports direct access to any word of the lexicon                            \n",
      "and takes only 300 kilobytes of random-access memory.                                                    \n"
     ]
    }
   ],
   "source": [
    "ans = []\n",
    "pattern = np.array([[\"t\", \" \", \"h\"], [\"t\", \" \", \"h\"]])\n",
    "ans += match_2d(pattern, text)\n",
    "\n",
    "pattern = np.array([[\"t\", \" \", \"h\"], [\"t\", \" \", \"h\"]])\n",
    "ans += match_2d(pattern, text)\n",
    "\n",
    "show(ans, text, pattern.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Wybierz przynajmniej 4 litery (małe). Znajdź wszystkie wystąpienia tej litery w załączonym pliku\n",
    "   \"haystack.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba wystąpień\n",
      "'a': 397\n",
      "'b': 56\n",
      "'c': 213\n",
      "'d': 137\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "text = np.array(Image.open(\"haystack.png\").convert(\"L\"))\n",
    "pat_a = np.array(Image.open(\"a.png\").convert(\"L\"))\n",
    "pat_b = np.array(Image.open(\"b.png\").convert(\"L\"))\n",
    "pat_c = np.array(Image.open(\"c.png\").convert(\"L\"))\n",
    "pat_d = np.array(Image.open(\"d.png\").convert(\"L\"))\n",
    "\n",
    "print(\"Liczba wystąpień\")\n",
    "print(\"'a':\", len(match_2d(pat_a, text)))\n",
    "print(\"'b':\", len(match_2d(pat_b, text)))\n",
    "print(\"'c':\", len(match_2d(pat_c, text)))\n",
    "print(\"'d':\", len(match_2d(pat_d, text)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Znajdź wszystkie wystąpienia słowa \"p a t t e r n\" w haystack.png. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L. wystąpień 'p a t t e r n': 5\n"
     ]
    }
   ],
   "source": [
    "text = np.array(Image.open(\"haystack.png\").convert(\"L\"))\n",
    "pat = np.array(Image.open(\"pattern.png\").convert(\"L\"))\n",
    "print(\"L. wystąpień 'p a t t e r n' :\", len(match_2d(pat, text)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Porównaj czas budowania automatu i czas wyszukiwania dla różnych rozmiarów wzorca "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Pattern length (NxN)    Automaton build time [s]    Search time [s]\n",
      "----------------------  --------------------------  -----------------\n",
      "                    10                   0.0002066          0.0386464\n",
      "                    20                   0.000307           0.035057\n",
      "                    30                   0.0012827          0.0345387\n",
      "                    40                   0.0011188          0.0366719\n",
      "                    50                   0.0016381          0.0398655\n",
      "                    60                   0.0028601          0.041236\n",
      "                    70                   0.0044025          0.122103\n",
      "                    80                   0.0052552          0.0652718\n",
      "                    90                   0.0052992          0.0573399\n",
      "                   100                   0.0059585          0.132607\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tabulate import tabulate\n",
    "\n",
    "table = []\n",
    "\n",
    "text = open(\"haystack.txt\", \"r\").read().splitlines()\n",
    "alphabet = set(text)\n",
    "MAX_LEN = len(max(text, key=lambda x: len(x)))\n",
    "text = list(\n",
    "    map(lambda x: list(x), list(map(lambda x: x + \" \" * (MAX_LEN - len(x)), text)))\n",
    ")\n",
    "text = np.array(text)\n",
    "\n",
    "for pat_len in range(10, 110, 10):\n",
    "    pattern = text[:pat_len, :pat_len]\n",
    "    start = time.perf_counter()\n",
    "    Trie(pattern).build_automaton(alphabet)\n",
    "    end = time.perf_counter()\n",
    "    build_time = end - start\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    match_2d(pattern, text)\n",
    "    end = time.perf_counter()\n",
    "    search_time = end - start\n",
    "\n",
    "    table.append((pat_len, build_time, search_time))\n",
    "\n",
    "\n",
    "print(\n",
    "    tabulate(\n",
    "        table,\n",
    "        headers=[\"Pattern length (NxN)\", \"Automaton build time [s]\", \"Search time [s]\"],\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Podziel plik na 2, 4 i 8 fragmentów (w poziomie) i porównaj czas przeszukiwania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the simplest and n a t u r a l type\n",
      "of written texts. This type of d a t a is \n",
      "be written down as a long sequence of char\n",
      "is called a text. T h e texts are central \n",
      "provide facilities for t h e manipulation \n",
      "objects t h a t are quite large. For examp\n",
      "t h a n a million characters. Text algorit\n",
      "information processing. Many text editors \n",
      "facilities for processing texts. In biolog\n",
      "of molecular sequences. T h e complexity o\n",
      "central and most studied problems in theor\n",
      "be said t h a t it is the domain in which \n",
      "each other.                               \n",
      "T h e basic textual problem in stringology\n",
      "used to access information and, no doubt, \n",
      "are solving this problem as a frequently u\n",
      "system. P a t t e r n matching is comparab\n",
      "arithmetic operations.                    \n",
      "Consider the problem of a reader of the Fr\n",
      "who wants all entries related to the n a m\n",
      "a n example of a p a t t e r n matching pr\n",
      "the n a m e \"Marie-Curie-Sklodowska\" is th\n",
      "find a string called a pattern of length m\n",
      "greater t h a n m. T h e p a t t e r n can\n",
      "a set of strings and not just a single wor\n",
      "genetics the p a t t e r n can correspond \n",
      "                                          \n",
      "T h e search of words or p a t t e r n s i\n",
      "t h a n the previous pattern-matching mech\n",
      "are organized in order to speed u p the ac\n",
      "of the same question is given by indexes. \n",
      "index of chosen terms t h a t gives pointe\n",
      "in the index. T h e algorithms involved in\n",
      "specific group. T h e use of dictionaries \n",
      "language processing. Lexicons of programmi\n",
      "representation is not a difficult problem \n",
      "To the contrary, English contains approxim\n",
      "t h a t if inflected forms are considered.\n",
      "t h a n 700,000 words. T h e representatio\n",
      "problem a bit more challenging.           \n",
      "A simple use of dictionaries is illustrate\n",
      "command, spell, reports the words in its i\n",
      "con. This rough approach does not yield a \n",
      "it helps to find typing errors. T h e lexi\n",
      "mately 70,000 entries stored within less t\n",
      "memory. Quick access to lexicons is a nece\n",
      "parsers. T h e d a t a structure useful fo\n",
      "book indexes correspond to d a t a structu\n",
      "(presumably long) text. We consider proble\n",
      "such structures: suffix t r e e s , d i r \n",
      "t o m a t a , suffix arrays. T h e PAT    \n",
      "tool developed at the N O E D Center      \n",
      "(Waterloo, Canada) is an implementation of\n",
      "to work on large texts. There are several \n",
      "some understanding of phrases in n a t u r\n",
      "systems, interactive software, a n d chara\n",
      "An image scanner is a kind of photocopier.\n",
      "version of a n image. W h e n the image is\n",
      "scanner must be in a digital form availabl\n",
      "of a digitized image of a text into a usua\n",
      "is realized by a n Optical Character Recog\n",
      "an O C R can be 50 times faster t h a n re\n",
      "O C R softwares are likely to become more \n",
      "a high degree of imprecision. T h e averag\n",
      "characters is approximately one percent. E\n",
      "small, this means t h a t scanning a book \n",
      "line. This is compared with the usually ve\n",
      "by specialists. Technical improvements on \n",
      "certain kinds of errors occurring on scann\n",
      "cannot alleviate the problem associated wi\n",
      "Reduction of the number of errors can thus\n",
      "context of the characters, which assumes s\n",
      "of the text. Image processing is related t\n",
      "pattern matching. Another related problem \n",
      "subimages, which is discussed in this book\n",
      "of basic factors.                         \n",
      "The theoretical approach to the representa\n",
      "of trees or finite state automata. It appe\n",
      "efficient. This shows the practical import\n",
      "approach to text problems. At LITP (Paris)\n",
      "we have shown that the use of automata to \n",
      "efficient. Experiments have been done on a\n",
      "(Paris). The representation supports direc\n",
      "and takes only 300 kilobytes of random-acc\n",
      "One of the simplest a\n",
      "of written texts. Thi\n",
      "be written down as a \n",
      "is called a text. T h\n",
      "provide facilities fo\n",
      "objects t h a t are q\n",
      "t h a n a million cha\n",
      "information processin\n",
      "facilities for proces\n",
      "of molecular sequence\n",
      "central and most stud\n",
      "be said t h a t it is\n",
      "each other.          \n",
      "T h e basic textual p\n",
      "used to access inform\n",
      "are solving this prob\n",
      "system. P a t t e r n\n",
      "arithmetic operations\n",
      "Consider the problem \n",
      "who wants all entries\n",
      "a n example of a p a \n",
      "the n a m e \"Marie-Cu\n",
      "find a string called \n",
      "greater t h a n m. T \n",
      "a set of strings and \n",
      "genetics the p a t t \n",
      "                     \n",
      "T h e search of words\n",
      "t h a n the previous \n",
      "are organized in orde\n",
      "of the same question \n",
      "index of chosen terms\n",
      "in the index. T h e a\n",
      "specific group. T h e\n",
      "language processing. \n",
      "representation is not\n",
      "To the contrary, Engl\n",
      "t h a t if inflected \n",
      "t h a n 700,000 words\n",
      "problem a bit more ch\n",
      "A simple use of dicti\n",
      "command, spell, repor\n",
      "con. This rough appro\n",
      "it helps to find typi\n",
      "mately 70,000 entries\n",
      "memory. Quick access \n",
      "parsers. T h e d a t \n",
      "book indexes correspo\n",
      "(presumably long) tex\n",
      "such structures: suff\n",
      "t o m a t a , suffix \n",
      "tool developed at the\n",
      "(Waterloo, Canada) is\n",
      "to work on large text\n",
      "some understanding of\n",
      "systems, interactive \n",
      "An image scanner is a\n",
      "version of a n image.\n",
      "scanner must be in a \n",
      "of a digitized image \n",
      "is realized by a n Op\n",
      "an O C R can be 50 ti\n",
      "O C R softwares are l\n",
      "a high degree of impr\n",
      "characters is approxi\n",
      "small, this means t h\n",
      "line. This is compare\n",
      "by specialists. Techn\n",
      "certain kinds of erro\n",
      "cannot alleviate the \n",
      "Reduction of the numb\n",
      "context of the charac\n",
      "of the text. Image pr\n",
      "pattern matching. Ano\n",
      "subimages, which is d\n",
      "of basic factors.    \n",
      "The theoretical appro\n",
      "of trees or finite st\n",
      "efficient. This shows\n",
      "approach to text prob\n",
      "we have shown that th\n",
      "efficient. Experiment\n",
      "(Paris). The represen\n",
      "and takes only 300 ki\n",
      "One of the\n",
      "of written\n",
      "be written\n",
      "is called \n",
      "provide fa\n",
      "objects t \n",
      "t h a n a \n",
      "informatio\n",
      "facilities\n",
      "of molecul\n",
      "central an\n",
      "be said t \n",
      "each other\n",
      "T h e basi\n",
      "used to ac\n",
      "are solvin\n",
      "system. P \n",
      "arithmetic\n",
      "Consider t\n",
      "who wants \n",
      "a n exampl\n",
      "the n a m \n",
      "find a str\n",
      "greater t \n",
      "a set of s\n",
      "genetics t\n",
      "          \n",
      "T h e sear\n",
      "t h a n th\n",
      "are organi\n",
      "of the sam\n",
      "index of c\n",
      "in the ind\n",
      "specific g\n",
      "language p\n",
      "representa\n",
      "To the con\n",
      "t h a t if\n",
      "t h a n 70\n",
      "problem a \n",
      "A simple u\n",
      "command, s\n",
      "con. This \n",
      "it helps t\n",
      "mately 70,\n",
      "memory. Qu\n",
      "parsers. T\n",
      "book index\n",
      "(presumabl\n",
      "such struc\n",
      "t o m a t \n",
      "tool devel\n",
      "(Waterloo,\n",
      "to work on\n",
      "some under\n",
      "systems, i\n",
      "An image s\n",
      "version of\n",
      "scanner mu\n",
      "of a digit\n",
      "is realize\n",
      "an O C R c\n",
      "O C R soft\n",
      "a high deg\n",
      "characters\n",
      "small, thi\n",
      "line. This\n",
      "by special\n",
      "certain ki\n",
      "cannot all\n",
      "Reduction \n",
      "context of\n",
      "of the tex\n",
      "pattern ma\n",
      "subimages,\n",
      "of basic f\n",
      "The theore\n",
      "of trees o\n",
      "efficient.\n",
      "approach t\n",
      "we have sh\n",
      "efficient.\n",
      "(Paris). T\n",
      "and takes \n"
     ]
    }
   ],
   "source": [
    "text_2 = text.T[:len(text) // 2].T\n",
    "text_4 = text.T[:len(text) // 4].T\n",
    "text_8 = text.T[:len(text) // 8].T\n",
    "\n",
    "print(\"\\n\".join([\"\".join(l) for l in text_2.tolist()]))\n",
    "print(\"\\n\".join([\"\".join(l) for l in text_4.tolist()]))\n",
    "print(\"\\n\".join([\"\".join(l) for l in text_8.tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  No. parts    Search time [s]\n",
      "-----------  -----------------\n",
      "          2          0.0140266\n",
      "          4          0.0063591\n",
      "          8          0.0028982\n"
     ]
    }
   ],
   "source": [
    "pattern = text[:20, :20]\n",
    "table = []\n",
    "\n",
    "start = time.perf_counter()\n",
    "match_2d(pattern, text_2)\n",
    "end = time.perf_counter()\n",
    "search_time = end - start\n",
    "\n",
    "table.append((\"2\", search_time))\n",
    "\n",
    "start = time.perf_counter()\n",
    "match_2d(pattern, text_4)\n",
    "end = time.perf_counter()\n",
    "search_time = end - start\n",
    "\n",
    "table.append((\"4\", search_time))\n",
    "\n",
    "start = time.perf_counter()\n",
    "match_2d(pattern, text_8)\n",
    "end = time.perf_counter()\n",
    "search_time = end - start\n",
    "\n",
    "table.append((\"8\", search_time))\n",
    "\n",
    "print(tabulate(table, headers=[\"No. parts\", \"Search time [s]\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
