{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Any, Sequence\n",
    "from functools import partial\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Zaimplementuj przynajmniej 3 \"metryki\" spośród wymienionych: cosinusowa, LCS,\n",
    "   DICE, euklidesowa, Levenshteina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text: str) -> str:\n",
    "    # Your code here: Convert the text to lowercase. Remove all punctuation\n",
    "    # marks;\n",
    "\n",
    "    from string import punctuation\n",
    "\n",
    "    text = text.lower().translate(str.maketrans(\"\", \"\", punctuation))\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def text_to_vec(docs: list[str]) -> list[list[int]]:\n",
    "    # Your code here: Convert documents to numerical vectors. Preprocess\n",
    "    # documents with the preprocess() function. Represent documents as vectors\n",
    "    # of word frequencies, you will need to extract a vocabulary from all the\n",
    "    # documents.\n",
    "    freq_vecs = []\n",
    "\n",
    "    from functools import reduce\n",
    "\n",
    "    bag_of_words = {\n",
    "        word: 0 for word in preprocess(reduce(lambda x, y: x + \" \" + y, docs)).split()\n",
    "    }\n",
    "\n",
    "    for text in docs:\n",
    "        for word in bag_of_words:\n",
    "            bag_of_words[word] = 0\n",
    "\n",
    "        for word in preprocess(text).split():\n",
    "            bag_of_words[word] += 1\n",
    "\n",
    "        v = list(bag_of_words.values())\n",
    "        freq_vecs.append(np.array(v))\n",
    "\n",
    "    return freq_vecs\n",
    "\n",
    "\n",
    "def levenshtein(seq_a: Sequence[Any], seq_b: Sequence[Any]) -> int:\n",
    "    # Your code here:\n",
    "    # Implement the Levenshtein distance calculation.\n",
    "    # It should work on any sequences, not only on strings.\n",
    "\n",
    "    m, n = len(seq_a), len(seq_b)\n",
    "    d = [[None for _ in range(n)] for _ in range(m)]\n",
    "\n",
    "    for i in range(m):\n",
    "        d[i][0] = i\n",
    "\n",
    "    for j in range(n):\n",
    "        d[0][j] = j\n",
    "\n",
    "    for i in range(1, m):\n",
    "        for j in range(1, n):\n",
    "            cost = 0 if seq_a[i] == seq_b[j] else 1\n",
    "            min_cost = min(\n",
    "                d[i - 1][j] + 1,  # deletion\n",
    "                d[i][j - 1] + 1,  # insertion\n",
    "                d[i - 1][j - 1] + cost,  # change\n",
    "            )\n",
    "            d[i][j] = min_cost\n",
    "\n",
    "    return d[m - 1][n - 1]\n",
    "\n",
    "\n",
    "def metric(x, y, type=\"euclidean\"):\n",
    "    match type:\n",
    "\n",
    "        case \"euclidean\":\n",
    "            vec_a, vec_b = text_to_vec([x, y])\n",
    "\n",
    "            return np.linalg.norm(vec_a - vec_b)\n",
    "\n",
    "        case \"levenshtein\":\n",
    "            seq_a = preprocess(x).split()\n",
    "            seq_b = preprocess(y).split()\n",
    "\n",
    "            return levenshtein(seq_a, seq_b)\n",
    "\n",
    "        case _:\n",
    "            raise Exception(f\"Unimplemented metric of type {type}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Zaimplementuj przynajmniej 1 sposoby oceny jakości klasteryzacji (np. indeks\n",
    "   Daviesa-Bouldina)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DB_index(clusters, d):\n",
    "    \"\"\"Function which calculates Davies-Bouldin index for a given clusterization\n",
    "\n",
    "    Args:\n",
    "        clusters (dict): dict of clusters\n",
    "        d (function: str, str -> float): distance between strings\n",
    "\n",
    "    Returns:\n",
    "        float: DB index\n",
    "    \"\"\"\n",
    "    from numpy.linalg import norm\n",
    "\n",
    "    n_clusters = len(clusters)\n",
    "    centroids = {}\n",
    "    avg_distances = {}\n",
    "\n",
    "    for name, docs in clusters.items():\n",
    "        vectors = text_to_vec(docs)\n",
    "\n",
    "        geo_center = sum(vectors) / len(vectors)\n",
    "        centroid_idx, min_centroid_dist = 0, norm(geo_center - vectors[0])\n",
    "\n",
    "        for i, v in enumerate(vectors):\n",
    "            dist = norm(geo_center - v)\n",
    "            if dist < min_centroid_dist:\n",
    "                centroid_idx, min_centroid_dist = i, dist\n",
    "\n",
    "        centroids[name] = clusters[name][centroid_idx]\n",
    "\n",
    "    for name, docs in clusters.items():\n",
    "        avg_dist = 0\n",
    "        for text in docs:\n",
    "            avg_dist += d(centroids[name], text)\n",
    "        avg_dist /= len(docs)\n",
    "\n",
    "        avg_distances[name] = avg_dist\n",
    "\n",
    "    db_index = 0\n",
    "    for i, name_i in enumerate(clusters):\n",
    "        max_ratio = 0\n",
    "        for j, name_j in enumerate(clusters):\n",
    "            if i != j:\n",
    "                ratio = (avg_distances[name_i] + avg_distances[name_j]) / (\n",
    "                    d(centroids[name_i], centroids[name_j])\n",
    "                )\n",
    "                max_ratio = max(max_ratio, ratio)\n",
    "        db_index += max_ratio\n",
    "    \n",
    "    db_index /= n_clusters\n",
    "\n",
    "    return db_index\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Wykonaj klasteryzację zawartości załączonego pliku (lines.txt) przy użyciu\n",
    "   metryk zaimplementowanych w pkt. 1. Każda linia to adres pocztowy firmy,\n",
    "   różne sposoby zapisu tego samego adresu powinny się znaleźć w jednym\n",
    "   klastrze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lines.txt\", \"r\") as f:\n",
    "    vectors = f.readlines()\n",
    "\n",
    "preprocessed_vectors = []\n",
    "for v in vectors:\n",
    "    preprocessed_vectors.append(preprocess(v))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porównaj jakość wyników sposobami zaimplementowanymi w pkt. 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.877585893366325"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(\"clusters.txt\", \"r\").read().splitlines()\n",
    "lines = list(filter(lambda text: text != \"\", lines))\n",
    "\n",
    "n_clusters = len(list(filter(lambda text: text == \"##########\", lines)))\n",
    "d = partial(metric, type=\"euclidean\")\n",
    "model_clusters = {i: [] for i in range(n_clusters)}\n",
    "\n",
    "i = 0\n",
    "for text in lines:\n",
    "    if text == \"##########\":\n",
    "        if len(model_clusters[i]) < 5:\n",
    "            del model_clusters[i]\n",
    "        i += 1\n",
    "    else:\n",
    "        model_clusters[i].append(text)\n",
    "\n",
    "DB_index(model_clusters, d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
