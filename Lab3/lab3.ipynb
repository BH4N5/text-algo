{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorium 3\n",
    "#### Bartosz Hanc\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Zaimplementuj algorytm obliczania odległości edycyjnej w taki sposób, aby możliwe było określenie\n",
    "   przynajmniej jednej sekwencji edycji (dodanie, usunięcie, zmiana znaku), która pozwala w\n",
    "   minimalnej liczbie kroków, przekształcić jeden łańcuch w drugi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Levenshtein_dist(s1: str, s2: str) -> int:\n",
    "    m, n = len(s1), len(s2)\n",
    "    s1 = \" \" + s1\n",
    "    s2 = \" \" + s2\n",
    "    d = [[None for _ in range(n + 1)] for _ in range(m + 1)]\n",
    "    parent = [[None for _ in range(n + 1)] for _ in range(m + 1)]\n",
    "    operation = [[None for _ in range(n + 1)] for _ in range(m + 1)]\n",
    "\n",
    "    for i in range(m + 1):\n",
    "        d[i][0] = i\n",
    "        if i > 0:\n",
    "            operation[i][0] = (\"delete all\", i)\n",
    "\n",
    "    for j in range(n + 1):\n",
    "        d[0][j] = j\n",
    "        if j > 0:\n",
    "            operation[0][j] = (\"insert all\", -1, s2[1:j+1])\n",
    "\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            cost = 0 if s1[i] == s2[j] else 1\n",
    "            min_cost = min(\n",
    "                d[i - 1][j] + 1,  # deletion\n",
    "                d[i][j - 1] + 1,  # insertion\n",
    "                d[i - 1][j - 1] + cost,  # change\n",
    "            )\n",
    "\n",
    "            if min_cost == d[i - 1][j] + 1:\n",
    "                operation[i][j] = (\"delete\", i - 1)\n",
    "                parent[i][j] = (i - 1, j)\n",
    "\n",
    "            elif min_cost == d[i][j - 1] + 1:\n",
    "                operation[i][j] = (\"insert\", i - 1, s2[j])\n",
    "                parent[i][j] = (i, j - 1)\n",
    "\n",
    "            elif min_cost == d[i - 1][j - 1] + 1:\n",
    "                operation[i][j] = (\"change\", i - 1, s2[j])\n",
    "                parent[i][j] = (i - 1, j - 1)\n",
    "\n",
    "            else:\n",
    "                parent[i][j] = (i - 1, j - 1)\n",
    "\n",
    "            d[i][j] = min_cost\n",
    "\n",
    "    steps = []\n",
    "    i, j = m, n\n",
    "    while parent[i][j] != None:\n",
    "        if operation[i][j] != None:\n",
    "            steps.append(operation[i][j])\n",
    "        i, j = parent[i][j]\n",
    "    if operation[i][j] != None:\n",
    "        steps.append(operation[i][j])\n",
    "\n",
    "    return d[m][n], steps[::-1]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Na podstawie poprzedniego punktu zaimplementuj prostą wizualizację działania algorytmu, poprzez\n",
    "   wskazanie kolejnych wersji pierwszego łańcucha, w których dokonywana jest określona zmiana.\n",
    "   \"Wizualizacja\" może działać w trybie tekstowym. Np. zmiana łańcuch \"los\" w \"kloc\" może być\n",
    "   zrealizowana następująco:\n",
    "    1. \\*k\\*los (dodanie litery k)\n",
    "    2. klo\\*c\\* (zamiana s->c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_steps(s1: str, s2: str) -> None:\n",
    "    dist, steps = Levenshtein_dist(s1, s2)\n",
    "    s, di, n = s1, 0, 1\n",
    "\n",
    "    print(f\"{s1} -> {s2}\")\n",
    "    print(f\"Levenshtein distance: {dist}\")\n",
    "\n",
    "    for step in steps:\n",
    "        match step[0]:\n",
    "\n",
    "            case \"delete\":\n",
    "                i = step[1]\n",
    "                print(f\"{n}. Delete: {s[:i+di]}[{s[i+di]}]{s[i+di+1:]}\")\n",
    "                s = s[: i + di] + s[i + di + 1 :]\n",
    "                di -= 1\n",
    "\n",
    "            case \"insert\":\n",
    "                i, char = step[1], step[2]\n",
    "                print(f\"{n}. Insert: {s[:i+di+1]}[{char}]{s[i+di+1:]}\")\n",
    "                s = s[: i + di + 1] + char + s[i + di + 1 :]\n",
    "                di += 1\n",
    "\n",
    "            case \"change\":\n",
    "                i, char = step[1], step[2]\n",
    "                print(f\"{n}. Change: {s[:i+di]}[{s[i+di]}->{char}]{s[i+di+1:]}\")\n",
    "                s = s[: i + di] + char + s[i + di + 1 :]\n",
    "\n",
    "            case \"insert all\":\n",
    "                chars = step[2]\n",
    "                print(f\"{n}. Insert: [{chars}]{s}\")\n",
    "                s = chars + s\n",
    "                di += len(chars)\n",
    "\n",
    "            case \"delete all\":\n",
    "                i = step[1]\n",
    "                print(f\"{n}. Delete [{s[:i]}]{s[i:]}\")\n",
    "                s = s[i:]\n",
    "                di -= i\n",
    "\n",
    "        n += 1\n",
    "\n",
    "    print(f\"{s} == {s2} ({s == s2})\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Przedstaw wynik działania algorytmu z p. 2 dla następujących par łańcuchów:\n",
    "    * los - kloc\n",
    "    * Łódź - Lodz\n",
    "    * kwintesencja - quintessence\n",
    "    * ATGAATCTTACCGCCTCG - ATGAGGCTCTGGCCCCTG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "los -> kloc\n",
      "Levenshtein distance: 2\n",
      "1. Insert: [k]los\n",
      "2. Change: klo[s->c]\n",
      "kloc == kloc (True)\n",
      "__________________________________________\n",
      "Łódź -> Lodz\n",
      "Levenshtein distance: 3\n",
      "1. Change: [Ł->L]ódź\n",
      "2. Change: L[ó->o]dź\n",
      "3. Change: Lod[ź->z]\n",
      "Lodz == Lodz (True)\n",
      "__________________________________________\n",
      "kwintesencja -> quintessence\n",
      "Levenshtein distance: 5\n",
      "1. Change: [k->q]wintesencja\n",
      "2. Change: q[w->u]intesencja\n",
      "3. Insert: quintes[s]encja\n",
      "4. Change: quintessenc[j->e]a\n",
      "5. Delete: quintessence[a]\n",
      "quintessence == quintessence (True)\n",
      "__________________________________________\n",
      "ATGAATCTTACCGCCTCG -> ATGAGGCTCTGGCCCCTG\n",
      "Levenshtein distance: 7\n",
      "1. Change: ATGA[A->G]TCTTACCGCCTCG\n",
      "2. Change: ATGAG[T->G]CTTACCGCCTCG\n",
      "3. Insert: ATGAGGCT[C]TACCGCCTCG\n",
      "4. Change: ATGAGGCTCT[A->G]CCGCCTCG\n",
      "5. Insert: ATGAGGCTCTG[G]CCGCCTCG\n",
      "6. Delete: ATGAGGCTCTGGCC[G]CCTCG\n",
      "7. Delete: ATGAGGCTCTGGCCCCT[C]G\n",
      "ATGAGGCTCTGGCCCCTG == ATGAGGCTCTGGCCCCTG (True)\n",
      "__________________________________________\n"
     ]
    }
   ],
   "source": [
    "for s1, s2 in (\n",
    "    (\"los\", \"kloc\"),\n",
    "    (\"Łódź\", \"Lodz\"),\n",
    "    (\"kwintesencja\", \"quintessence\"),\n",
    "    (\"ATGAATCTTACCGCCTCG\", \"ATGAGGCTCTGGCCCCTG\"),\n",
    "):\n",
    "    show_steps(s1, s2)\n",
    "    print(\"_\" * 42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Zaimplementuj algorytm obliczania najdłuższego wspólnego podciągu dla pary ciągów elementów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcs(A, B):\n",
    "    n, m = len(A), len(B)\n",
    "    C = [[None for _ in range(m + 1)] for _ in range(n + 1)]\n",
    "\n",
    "    for i in range(n + 1):\n",
    "        C[i][0] = 0\n",
    "\n",
    "    for i in range(m + 1):\n",
    "        C[0][i] = 0\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            if A[i - 1] == B[j - 1]:\n",
    "                C[i][j] = C[i - 1][j - 1] + 1\n",
    "            else:\n",
    "                C[i][j] = max(C[i - 1][j], C[i][j - 1])\n",
    "\n",
    "    res = []\n",
    "    i, j = n, m\n",
    "    while i != 0 and j != 0:\n",
    "        if C[i - 1][j] == C[i][j]:\n",
    "            i, j = i - 1, j\n",
    "        elif C[i][j - 1] == C[i][j]:\n",
    "            i, j = i, j - 1\n",
    "        else:\n",
    "            res.append(A[i - 1])\n",
    "            i, j = i - 1, j - 1\n",
    "\n",
    "    return res[::-1]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Korzystając z gotowego tokenizera (np. spaCy - https://spacy.io/api/tokenizer) dokonaj podziału\n",
    "   załączonego tekstu na tokeny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.pl import Polish\n",
    "\n",
    "nlp = Polish()\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "with open(\"romeo-i-julia-700.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "tokens = tokenizer(text)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Stwórz 2 wersje załączonego tekstu, w których usunięto 3% losowych tokenów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choices\n",
    "\n",
    "\n",
    "def rm_random(tokens, p=0.03):\n",
    "    rnd_tokens = set(choices(list(tokens), k=int(p * len(tokens))))\n",
    "    out_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in rnd_tokens:\n",
    "            out_tokens.append(token)\n",
    "\n",
    "    return out_tokens\n",
    "\n",
    "\n",
    "tokens1 = rm_random(tokens)\n",
    "tokens2 = rm_random(tokens)\n",
    "\n",
    "with open(\"text1.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for token in tokens1:\n",
    "        file.write(token.text_with_ws)\n",
    "\n",
    "with open(\"text2.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for token in tokens2:\n",
    "        file.write(token.text_with_ws)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Oblicz długość najdłuższego podciągu wspólnych tokenów dla tych tekstów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2139\n"
     ]
    }
   ],
   "source": [
    "print(len(lcs(tokens1, tokens2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Korzystając z algorytmu z punktu 4 skonstruuj narzędzie, o działaniu podobnym do narzędzia\n",
    "   `diff`, tzn. wskazującego w dwóch plikach linie, które się różnią. Na wyjściu narzędzia powinny\n",
    "   znaleźć się elementy, które nie należą do najdłuższego wspólnego podciągu. Należy wskazać, skąd\n",
    "   dana linia pochodzi (< > - pierwszy/drugi plik) oraz numer linii w danym pliku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff(file1, file2):\n",
    "    with open(file1, \"r\", encoding=\"utf-8\") as file:\n",
    "        text1 = file.read()\n",
    "    with open(file2, \"r\", encoding=\"utf-8\") as file:\n",
    "        text2 = file.read()\n",
    "\n",
    "    text1 = text1.split(\"\\n\")\n",
    "    text2 = text2.split(\"\\n\")\n",
    "    common = lcs(text1, text2)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Przedstaw wynik działania narzędzia na tekstach z punktu 6. Zwróć uwagę na dodanie znaków\n",
    "   przejścia do nowej linii, które są usuwane w trakcie tokenizacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff(\"text1.txt\", \"text2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
